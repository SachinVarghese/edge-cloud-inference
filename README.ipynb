{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Edge Cloud Joint Inference with Seldon Core and Tempo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Description"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "!conda env create --name edge-cloud-inference --file ./conda/edge-cloud-inference.yaml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "!conda activate edge-cloud-inference"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train models "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install git+https://github.com/SachinVarghese/tempo.git@tempo-k8s-nodename#egg=mlops-tempo&subdirectory=tempo"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "from tempo.utils import logger\n",
    "import logging\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "ARTIFACTS_FOLDER = os.getcwd()+\"/artifacts\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# %load src/train.py\n",
    "from src.data import IrisData\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "EdgeModelFolder = \"edge\"\n",
    "CloudModelFolder = \"cloud\"\n",
    "\n",
    "\n",
    "def train_edge_model(data: IrisData, artifacts_folder: str):\n",
    "    logreg = LogisticRegression(C=1e5)\n",
    "    logreg.fit(data.X, data.y)\n",
    "    with open(f\"{artifacts_folder}/{EdgeModelFolder}/model.joblib\", \"wb\") as f:\n",
    "        joblib.dump(logreg, f)\n",
    "\n",
    "\n",
    "def train_cloud_model(data: IrisData, artifacts_folder: str):\n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(data.X, data.y)\n",
    "    clf.save_model(f\"{artifacts_folder}/{CloudModelFolder}/model.bst\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from src.data import IrisData\n",
    "from src.train import train_edge_model, train_cloud_model\n",
    "data = IrisData()\n",
    "train_edge_model(data, ARTIFACTS_FOLDER)\n",
    "train_cloud_model(data, ARTIFACTS_FOLDER)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sachin/miniconda3/envs/edge-cloud-inference/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:59:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Tempo artifacts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# %load src/tempo.py\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from src.train import CloudModelFolder, EdgeModelFolder\n",
    "\n",
    "from tempo.serve.metadata import ModelFramework, RuntimeOptions, KubernetesOptions\n",
    "from tempo.seldon.k8s import SeldonCoreOptions\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import Pipeline, PipelineModels\n",
    "from tempo.serve.utils import pipeline\n",
    "\n",
    "PipelineFolder = \"joint-classifier\"\n",
    "EdgePredictionTag = \"edge prediction\"\n",
    "CloudPredictionTag = \"cloud prediction\"\n",
    "\n",
    "edgeRuntimeOptions = RuntimeOptions()  # Docker Runtime\n",
    "edgeRuntimeOptions.k8s_options = KubernetesOptions(\n",
    "    replicas=1, namespace=\"production\", nodeName=\"edge-compute\",\n",
    ")\n",
    "\n",
    "\n",
    "cloudRuntimeOptions = SeldonCoreOptions()  # Kubernetes Runtime\n",
    "cloudRuntimeOptions.k8s_options = KubernetesOptions(\n",
    "    replicas=2,\n",
    "    namespace=\"production\",\n",
    "    nodeName=\"gke-kubeedge-cloudcore-default-pool-4dbe91a1-v7e5\",\n",
    ")\n",
    "\n",
    "\n",
    "def get_tempo_artifacts(artifacts_folder: str) -> Tuple[Pipeline, Model, Model]:\n",
    "\n",
    "    cloud_model = Model(\n",
    "        name=\"cloud-model\",\n",
    "        platform=ModelFramework.XGBoost,\n",
    "        local_folder=f\"{artifacts_folder}/{CloudModelFolder}\",\n",
    "        uri=\"s3://tempo/joint-inference/cloud\",\n",
    "        description=\"An Cloud based Iris classification model\",\n",
    "        runtime_options=cloudRuntimeOptions,\n",
    "    )\n",
    "\n",
    "    edge_model = Model(\n",
    "        name=\"edge-model\",\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=f\"{artifacts_folder}/{EdgeModelFolder}\",\n",
    "        uri=\"s3://tempo/joint-inference/edge\",\n",
    "        description=\"An Edge based Iris classification model\",\n",
    "        runtime_options=edgeRuntimeOptions,\n",
    "    )\n",
    "\n",
    "    @pipeline(\n",
    "        name=\"joint-classifier\",\n",
    "        uri=\"s3://tempo/basic/pipeline\",\n",
    "        local_folder=f\"{artifacts_folder}/{PipelineFolder}\",\n",
    "        models=PipelineModels(edge_inference=edge_model, cloud_inference=cloud_model),\n",
    "        description=\"A pipeline to make an edge based prediction or cloud based joint prediction for Iris classification\",\n",
    "        runtime_options=edgeRuntimeOptions,\n",
    "    )\n",
    "    def classifier(payload: np.ndarray) -> Tuple[np.ndarray, str]:\n",
    "        # Custom Logic for hard example mining based on threshold, IBT, Cross Entropy etc\n",
    "        res1 = classifier.models.edge_inference(input=payload)\n",
    "        if res1[0] == 1:\n",
    "            return res1, EdgePredictionTag\n",
    "        else:\n",
    "            return classifier.models.cloud_inference(input=payload), CloudPredictionTag\n",
    "\n",
    "    return classifier, edge_model, cloud_model\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from src.tempo import get_tempo_artifacts\n",
    "classifier, edge_model, cloud_model = get_tempo_artifacts(ARTIFACTS_FOLDER)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from tempo.serve.loader import save\n",
    "save(classifier)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/sachin/miniconda3/envs/tempo-ccf3b3d9-fe97-4bc0-96e8-ed2ea66cfcbf' to '/home/sachin/projects/mlops/edge-cloud-inference/artifacts/joint-classifier/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 19.5s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deploy to Docker"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "from tempo.serve.metadata import RuntimeOptions\n",
    "from tempo import deploy\n",
    "runtime_options = RuntimeOptions()\n",
    "remote_model = deploy(classifier, options=runtime_options)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make predictions "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edge"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "!docker run --rm --network=tempo curlimages/curl:7.78.0 -XPOST http://172.18.0.2:9000/v2/models/edge-model/infer -s -H \"Content-Type: application/json\" -d '{\"inputs\": [{ \"name\":\"dimensions\", \"data\": [0.3,0.6,4.2,3.1], \"datatype\": \"FP64\", \"shape\":[1,4] }]}'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\"model_name\":\"edge-model\",\"model_version\":null,\"id\":\"de4599d3-eee1-4a88-ab87-1b4a84a7262b\",\"parameters\":null,\"outputs\":[{\"name\":\"predict\",\"shape\":[1],\"datatype\":\"FP32\",\"parameters\":null,\"data\":[2]}]}"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cloud"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "!docker run --rm --network=tempo curlimages/curl:7.78.0 -XPOST http://172.18.0.3:9000/v2/models/cloud-model/infer -s -H \"Content-Type: application/json\" -d '{\"inputs\": [{ \"name\":\"dimensions\", \"data\": [0.3,0.6,4.2,3.1], \"datatype\": \"FP64\", \"shape\":[1,4] }]}'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\"model_name\":\"cloud-model\",\"model_version\":null,\"id\":\"1a2e0dcd-6f64-4c15-b65b-cf6ed58453b8\",\"parameters\":null,\"outputs\":[{\"name\":\"predict\",\"shape\":[1,3],\"datatype\":\"FP32\",\"parameters\":null,\"data\":[[0.007310844957828522,0.031725041568279266,0.9609640836715698]]}]}"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Joint Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "!docker run --rm --network=tempo curlimages/curl:7.78.0 -XPOST http://172.18.0.4:9000/v2/models/joint-classifier/infer -s -H \"Content-Type: application/json\" -d '{\"inputs\": [{ \"name\":\"dimensions\", \"data\": [0.3,0.6,4.2,3.1], \"datatype\": \"FP64\", \"shape\":[1,4] }]}'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\"model_name\":\"joint-classifier\",\"model_version\":null,\"id\":\"77c13e4b-e184-4da6-b684-a89eca32ee00\",\"parameters\":null,\"outputs\":[{\"name\":\"output0\",\"shape\":[1,3],\"datatype\":\"FP32\",\"parameters\":null,\"data\":[0.007310844957828522,0.031725041568279266,0.9609640836715698]},{\"name\":\"output1\",\"shape\":[16],\"datatype\":\"BYTES\",\"parameters\":null,\"data\":[99,108,111,117,100,32,112,114,101,100,105,99,116,105,111,110]}]}"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deploy to Kubernetes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from tempo.examples.minio import create_minio_rclone\n",
    "import os\n",
    "create_minio_rclone(os.getcwd()+\"/setup/storageInit/rclone.conf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from tempo.serve.loader import upload\n",
    "upload(edge_model)\n",
    "upload(cloud_model)\n",
    "upload(classifier)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "!kubectl create ns production\n",
    "!kubectl apply -f src/rbac -n production"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error from server (AlreadyExists): namespaces \"production\" already exists\n",
      "secret/minio-secret configured\n",
      "serviceaccount/tempo-pipeline unchanged\n",
      "role.rbac.authorization.k8s.io/tempo-pipeline unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/tempo-pipeline-rolebinding unchanged\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from tempo.seldon.k8s import SeldonCoreOptions\n",
    "runtime_options = SeldonCoreOptions()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from tempo import deploy\n",
    "remote_model = deploy(classifier, options=runtime_options)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "k8s_runtime = SeldonKubernetesRuntime(runtime_options)\n",
    "models = k8s_runtime.list_models(namespace=\"production\")\n",
    "print(\"Name\\t\\tDescription\")\n",
    "for model in models:\n",
    "    details = model.get_tempo().model_spec.model_details\n",
    "    print(f\"{details.name}\\t{details.description}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Name\t\tDescription\n",
      "cloud-model\tAn Cloud based Iris classification model\n",
      "edge-model\tAn Edge based Iris classification model\n",
      "joint-classifier\tA pipeline to make an edge based prediction or cloud based joint prediction for Iris classification\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edge"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "!docker run --rm curlimages/curl:7.78.0 -XPOST http://172.17.0.2:9000/v2/models/edge-model/infer -s -H \"Content-Type: application/json\" -d '{\"inputs\": [{ \"name\":\"dimensions\", \"data\": [0.3,0.6,4.2,3.1], \"datatype\": \"FP64\", \"shape\":[1,4] }]}'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\"model_name\":\"edge-model\",\"model_version\":\"v1\",\"id\":\"8cb79dfc-68ca-40e0-9fc9-d494e7b4a8f5\",\"parameters\":null,\"outputs\":[{\"name\":\"predict\",\"shape\":[1],\"datatype\":\"FP32\",\"parameters\":null,\"data\":[2]}]}"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cloud"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "import numpy as np\n",
    "models[0].predict(np.array([[0.3,0.6,4.2,3.1]])) # via cloud ingress"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.00731084, 0.03172504, 0.9609641 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Joint Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "remote_model.predict(np.array([[0.3,0.6,4.2,3.1]])) # Will fail\n",
    "# models[1].predict(np.array([[0.3,0.6,4.2,3.1]]))  # Will fail\n",
    "# models[2].predict(np.array([[0.3,0.6,4.2,3.1]]))  # Will fail"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "!docker run --rm curlimages/curl:7.78.0 -XPOST http://172.17.0.3:9000/v2/models/joint-classifier/infer -s -H \"Content-Type: application/json\" -d '{\"inputs\": [{ \"name\":\"dimensions\", \"data\": [0.3,0.6,4.2,3.1], \"datatype\": \"FP64\", \"shape\":[1,4] }]}'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\"model_name\":\"joint-classifier\",\"model_version\":null,\"id\":\"9c756d4e-959a-4ce7-b495-8d3404261b1f\",\"parameters\":null,\"outputs\":[{\"name\":\"output0\",\"shape\":[1,3],\"datatype\":\"FP32\",\"parameters\":null,\"data\":[0.007310844957828522,0.031725041568279266,0.9609640836715698]},{\"name\":\"output1\",\"shape\":[16],\"datatype\":\"BYTES\",\"parameters\":null,\"data\":[99,108,111,117,100,32,112,114,101,100,105,99,116,105,111,110]}]}"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "remote_model.undeploy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!kubectl delete ns production"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('edge-cloud-inference': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "interpreter": {
   "hash": "b13ebdd41a546de59ac116a2bc72dc22ec945364f745818ec8892fa6b1128e81"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}