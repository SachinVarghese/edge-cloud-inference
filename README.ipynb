{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Edge Cloud Joint Inference with Seldon Core and Tempo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Description"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "!conda env create --name edge-cloud-inference --file ./conda/edge-cloud-inference.yaml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "!conda activate edge-cloud-inference"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train models "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install git+https://github.com/SachinVarghese/tempo.git@tempo-k8s-nodename#egg=mlops-tempo&subdirectory=tempo"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "from tempo.utils import logger\n",
    "import logging\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "ARTIFACTS_FOLDER = os.getcwd()+\"/artifacts\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# %load src/train.py\n",
    "from src.data import IrisData\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "EdgeModelFolder = \"edge\"\n",
    "CloudModelFolder = \"cloud\"\n",
    "\n",
    "\n",
    "def train_edge_model(data: IrisData, artifacts_folder: str):\n",
    "    logreg = LogisticRegression(C=1e5)\n",
    "    logreg.fit(data.X, data.y)\n",
    "    with open(f\"{artifacts_folder}/{EdgeModelFolder}/model.joblib\", \"wb\") as f:\n",
    "        joblib.dump(logreg, f)\n",
    "\n",
    "\n",
    "def train_cloud_model(data: IrisData, artifacts_folder: str):\n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(data.X, data.y)\n",
    "    clf.save_model(f\"{artifacts_folder}/{CloudModelFolder}/model.bst\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from src.data import IrisData\n",
    "from src.train import train_edge_model, train_cloud_model\n",
    "data = IrisData()\n",
    "train_edge_model(data, ARTIFACTS_FOLDER)\n",
    "train_cloud_model(data, ARTIFACTS_FOLDER)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sachin/miniconda3/envs/edge-cloud-inference/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[09:16:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Tempo artifacts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# %load src/tempo.py\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from src.train import CloudModelFolder, EdgeModelFolder\n",
    "\n",
    "from tempo.serve.metadata import ModelFramework, RuntimeOptions, KubernetesOptions\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import Pipeline, PipelineModels\n",
    "from tempo.serve.utils import pipeline\n",
    "\n",
    "PipelineFolder = \"joint-classifier\"\n",
    "EdgePredictionTag = \"edge prediction\"\n",
    "CloudPredictionTag = \"cloud prediction\"\n",
    "\n",
    "edgeKubernetesOptions = RuntimeOptions()\n",
    "edgeKubernetesOptions.k8s_options = KubernetesOptions(\n",
    "    replicas=1,\n",
    "    nodeName=\"edge-compute\",\n",
    "    namespace=\"production\",\n",
    "    authSecretName=\"minio-secret\",\n",
    ")\n",
    "\n",
    "\n",
    "cloudKubernetesOptions = RuntimeOptions()\n",
    "cloudKubernetesOptions.k8s_options = KubernetesOptions(\n",
    "    replicas=2,\n",
    "    nodeName=\"gke-kubeedge-cloudcore-default-pool-4dbe91a1-2t80\",\n",
    "    namespace=\"production\",\n",
    "    authSecretName=\"minio-secret\",\n",
    ")\n",
    "\n",
    "\n",
    "def get_tempo_artifacts(artifacts_folder: str) -> Tuple[Pipeline, Model, Model]:\n",
    "\n",
    "    edge_model = Model(\n",
    "        name=\"edge-model\",\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=f\"{artifacts_folder}/{EdgeModelFolder}\",\n",
    "        uri=\"s3://tempo/joint-inference/edge\",\n",
    "        description=\"An Edge based Iris classification model\",\n",
    "        runtime_options=edgeKubernetesOptions,\n",
    "    )\n",
    "\n",
    "    cloud_model = Model(\n",
    "        name=\"cloud-model\",\n",
    "        platform=ModelFramework.XGBoost,\n",
    "        local_folder=f\"{artifacts_folder}/{CloudModelFolder}\",\n",
    "        uri=\"s3://tempo/joint-inference/cloud\",\n",
    "        description=\"An Cloud based Iris classification model\",\n",
    "        runtime_options=cloudKubernetesOptions,\n",
    "    )\n",
    "\n",
    "    @pipeline(\n",
    "        name=\"joint-classifier\",\n",
    "        uri=\"s3://tempo/basic/pipeline\",\n",
    "        local_folder=f\"{artifacts_folder}/{PipelineFolder}\",\n",
    "        models=PipelineModels(edge_inference=edge_model, cloud_inference=cloud_model),\n",
    "        description=\"A pipeline to make an edge based prediction or cloud based joint prediction for Iris classification\",\n",
    "        runtime_options=edgeKubernetesOptions,\n",
    "    )\n",
    "    def classifier(payload: np.ndarray) -> Tuple[np.ndarray, str]:\n",
    "        # Custom Logic for hard example mining based on threshold, IBT, Cross Entropy etc\n",
    "        res1 = classifier.models.edge_inference(input=payload)\n",
    "        if res1[0] == 1:\n",
    "            return res1, EdgePredictionTag\n",
    "        else:\n",
    "            return classifier.models.cloud_inference(input=payload), CloudPredictionTag\n",
    "\n",
    "    return classifier, edge_model, cloud_model\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from src.tempo import get_tempo_artifacts\n",
    "classifier, edge_model, cloud_model = get_tempo_artifacts(ARTIFACTS_FOLDER)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from tempo.serve.loader import save\n",
    "save(classifier)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/sachin/miniconda3/envs/tempo-7207925c-a439-463b-a8f1-f9eb9a9f122f' to '/home/sachin/projects/mlops/edge-cloud-inference/artifacts/joint-classifier/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 26.7s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deploy to Kubernetes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from tempo.examples.minio import create_minio_rclone\n",
    "import os\n",
    "create_minio_rclone(os.getcwd()+\"/rclone.conf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from tempo.serve.loader import upload\n",
    "upload(edge_model)\n",
    "upload(cloud_model)\n",
    "upload(classifier)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "!kubectl create ns production\n",
    "!kubectl apply -f src/rbac -n production"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error from server (AlreadyExists): namespaces \"production\" already exists\n",
      "secret/minio-secret configured\n",
      "serviceaccount/tempo-pipeline unchanged\n",
      "role.rbac.authorization.k8s.io/tempo-pipeline unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/tempo-pipeline-rolebinding unchanged\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from tempo.serve.metadata import KubernetesOptions\n",
    "from tempo.seldon.k8s import SeldonCoreOptions\n",
    "runtime_options = SeldonCoreOptions()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from tempo import deploy\n",
    "remote_model = deploy(classifier, options=runtime_options)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "import numpy as np\n",
    "\n",
    "print(remote_model.predict(payload=np.array([[0, 0, 0, 0]])))\n",
    "print(remote_model.predict(payload=np.array([[1, 2, 3, 4]])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "k8s_runtime = SeldonKubernetesRuntime(runtime_options)\n",
    "models = k8s_runtime.list_models(namespace=\"production\")\n",
    "print(\"Name\\t\\tDescription\")\n",
    "for model in models:\n",
    "    details = model.get_tempo().model_spec.model_details\n",
    "    print(f\"{details.name}\\t{details.description}\")\n",
    "\n",
    "models[2].predict(payload=np.array([[1, 2, 3, 4]]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Name\t\tDescription\n",
      "cloud-model\tAn Cloud based Iris classification model\n",
      "edge-model\tAn Edge based Iris classification model\n",
      "joint-classifier\tA pipeline to make an edge based prediction or cloud based joint prediction for Iris classification\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'output0': array([[0.00847207, 0.03168793, 0.95984   ]], dtype=float32),\n",
       " 'output1': 'cloud prediction'}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "remote_model.undeploy()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tempo:Undeploying joint-classifier\n",
      "DEBUG:tempo:Loading external kubernetes config\n",
      "INFO:tempo:Undeploying edge-model\n",
      "DEBUG:tempo:Loading external kubernetes config\n",
      "INFO:tempo:Undeploying cloud-model\n",
      "DEBUG:tempo:Loading external kubernetes config\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('edge-cloud-inference': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "interpreter": {
   "hash": "b13ebdd41a546de59ac116a2bc72dc22ec945364f745818ec8892fa6b1128e81"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}